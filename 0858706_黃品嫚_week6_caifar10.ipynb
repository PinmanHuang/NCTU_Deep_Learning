{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(histories, key='loss'):\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                       '--', label=name.title()+' Val')\n",
    "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "                 label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([0,max(history.epoch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_history(histories, key='accuracy'):\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                       '--', label=name.title()+' Val')\n",
    "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "                 label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([0,max(history.epoch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "train_img_size = 2500\n",
    "for i in range(1, train_img_size+1):\n",
    "    img = load_img('./CIFAR10/finaltest/test ('+str(i)+').png')\n",
    "    if i == 1:\n",
    "        x_final = [img_to_array(img)]\n",
    "    else:\n",
    "        x_final = np.append(x_final, [img_to_array(img)], axis=0)\n",
    "\n",
    "\n",
    "# reshape\n",
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "x_final = x_final.reshape(x_final.shape[0], 32, 32, 3)\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_final = x_final.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "Number of images in x_train 50000\n",
      "Number of images in x_test 10000\n",
      "Number of images in x_final 2500\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])\n",
    "print('Number of images in x_final', x_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       ...,\n",
       "       [9],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# normalize -1~1\n",
    "x_train = (x_train-127.5)/127.5\n",
    "x_test = (x_test-127.5)/127.5\n",
    "x_final = (x_final-127.5)/127.5\n",
    "\n",
    "# validation\n",
    "x_val = x_train[-1000:]\n",
    "y_val = y_train[-1000:]\n",
    "x_train = x_train[:-1000]\n",
    "y_train = y_train[:-1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up image augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,345,066\n",
      "Trainable params: 1,343,146\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "383/382 [==============================] - 16s 43ms/step - loss: 1.7913 - acc: 0.4249 - val_loss: 2.2095 - val_acc: 0.2800\n",
      "Epoch 2/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 1.2343 - acc: 0.5716 - val_loss: 1.0301 - val_acc: 0.6500\n",
      "Epoch 3/100\n",
      "383/382 [==============================] - 15s 38ms/step - loss: 1.0316 - acc: 0.6367 - val_loss: 0.9411 - val_acc: 0.6780\n",
      "Epoch 4/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.8993 - acc: 0.6825 - val_loss: 0.8690 - val_acc: 0.7010\n",
      "Epoch 5/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.8199 - acc: 0.7104 - val_loss: 0.7072 - val_acc: 0.7620\n",
      "Epoch 6/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.7539 - acc: 0.7368 - val_loss: 0.7211 - val_acc: 0.7570\n",
      "Epoch 7/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.7053 - acc: 0.7531 - val_loss: 0.6844 - val_acc: 0.7600\n",
      "Epoch 8/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.6583 - acc: 0.7696 - val_loss: 0.5650 - val_acc: 0.8210\n",
      "Epoch 9/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.6196 - acc: 0.7840 - val_loss: 0.6828 - val_acc: 0.7730\n",
      "Epoch 10/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.5897 - acc: 0.7948 - val_loss: 0.5484 - val_acc: 0.8060\n",
      "Epoch 11/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.5611 - acc: 0.8057 - val_loss: 0.5594 - val_acc: 0.8200\n",
      "Epoch 12/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.5361 - acc: 0.8122 - val_loss: 0.5464 - val_acc: 0.8240\n",
      "Epoch 13/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.5198 - acc: 0.8210 - val_loss: 0.5772 - val_acc: 0.8050\n",
      "Epoch 14/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.4960 - acc: 0.8278 - val_loss: 0.5059 - val_acc: 0.8380\n",
      "Epoch 15/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.4720 - acc: 0.8370 - val_loss: 0.5300 - val_acc: 0.8370\n",
      "Epoch 16/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.4617 - acc: 0.8396 - val_loss: 0.4996 - val_acc: 0.8360\n",
      "Epoch 17/100\n",
      "383/382 [==============================] - 14s 38ms/step - loss: 0.4423 - acc: 0.8477 - val_loss: 0.4901 - val_acc: 0.8420\n",
      "Epoch 18/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.4312 - acc: 0.8490 - val_loss: 0.5326 - val_acc: 0.8280\n",
      "Epoch 19/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.4118 - acc: 0.8567 - val_loss: 0.5133 - val_acc: 0.8330\n",
      "Epoch 20/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.4064 - acc: 0.8585 - val_loss: 0.4592 - val_acc: 0.8540\n",
      "Epoch 21/100\n",
      "383/382 [==============================] - 15s 38ms/step - loss: 0.3917 - acc: 0.8641 - val_loss: 0.4621 - val_acc: 0.8370\n",
      "Epoch 22/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.3781 - acc: 0.8684 - val_loss: 0.5210 - val_acc: 0.8340\n",
      "Epoch 23/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.3793 - acc: 0.8673 - val_loss: 0.4773 - val_acc: 0.8400\n",
      "Epoch 24/100\n",
      "383/382 [==============================] - 15s 38ms/step - loss: 0.3665 - acc: 0.8731 - val_loss: 0.4213 - val_acc: 0.8500\n",
      "Epoch 25/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.3504 - acc: 0.8776 - val_loss: 0.4607 - val_acc: 0.8520\n",
      "Epoch 26/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.3470 - acc: 0.8778 - val_loss: 0.3970 - val_acc: 0.8660\n",
      "Epoch 27/100\n",
      "383/382 [==============================] - 15s 38ms/step - loss: 0.3433 - acc: 0.8807 - val_loss: 0.4033 - val_acc: 0.8670\n",
      "Epoch 28/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.3261 - acc: 0.8878 - val_loss: 0.4148 - val_acc: 0.8560\n",
      "Epoch 29/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.3182 - acc: 0.8893 - val_loss: 0.4049 - val_acc: 0.8630\n",
      "Epoch 30/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.3201 - acc: 0.8870 - val_loss: 0.3838 - val_acc: 0.8750\n",
      "Epoch 31/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.3088 - acc: 0.8910 - val_loss: 0.3888 - val_acc: 0.8600\n",
      "Epoch 32/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.3061 - acc: 0.8932 - val_loss: 0.3944 - val_acc: 0.8730\n",
      "Epoch 33/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.3009 - acc: 0.8944 - val_loss: 0.3947 - val_acc: 0.8660\n",
      "Epoch 34/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2957 - acc: 0.8985 - val_loss: 0.3887 - val_acc: 0.8770\n",
      "Epoch 35/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2876 - acc: 0.8990 - val_loss: 0.4018 - val_acc: 0.8730\n",
      "Epoch 36/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2796 - acc: 0.9025 - val_loss: 0.3820 - val_acc: 0.8740\n",
      "Epoch 37/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2786 - acc: 0.9027 - val_loss: 0.4007 - val_acc: 0.8690\n",
      "Epoch 38/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2736 - acc: 0.9045 - val_loss: 0.4122 - val_acc: 0.8630\n",
      "Epoch 39/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2635 - acc: 0.9085 - val_loss: 0.4247 - val_acc: 0.8680\n",
      "Epoch 40/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2644 - acc: 0.9070 - val_loss: 0.4012 - val_acc: 0.8800\n",
      "Epoch 41/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2584 - acc: 0.9105 - val_loss: 0.3814 - val_acc: 0.8780\n",
      "Epoch 42/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2552 - acc: 0.9100 - val_loss: 0.4026 - val_acc: 0.8640\n",
      "Epoch 43/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2542 - acc: 0.9112 - val_loss: 0.3959 - val_acc: 0.8710\n",
      "Epoch 44/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2473 - acc: 0.9131 - val_loss: 0.3905 - val_acc: 0.8740\n",
      "Epoch 45/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2432 - acc: 0.9154 - val_loss: 0.3801 - val_acc: 0.8820\n",
      "Epoch 46/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2370 - acc: 0.9176 - val_loss: 0.4275 - val_acc: 0.8640\n",
      "Epoch 47/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2333 - acc: 0.9173 - val_loss: 0.4266 - val_acc: 0.8670\n",
      "Epoch 48/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2370 - acc: 0.9168 - val_loss: 0.3726 - val_acc: 0.8830\n",
      "Epoch 49/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2311 - acc: 0.9182 - val_loss: 0.3837 - val_acc: 0.8900\n",
      "Epoch 50/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2267 - acc: 0.9202 - val_loss: 0.3613 - val_acc: 0.8920\n",
      "Epoch 51/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2219 - acc: 0.9232 - val_loss: 0.3917 - val_acc: 0.8820\n",
      "Epoch 52/100\n",
      "383/382 [==============================] - 15s 38ms/step - loss: 0.2243 - acc: 0.9215 - val_loss: 0.3980 - val_acc: 0.8770\n",
      "Epoch 53/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2130 - acc: 0.9255 - val_loss: 0.4097 - val_acc: 0.8820\n",
      "Epoch 54/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2094 - acc: 0.9266 - val_loss: 0.3641 - val_acc: 0.8840\n",
      "Epoch 55/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2156 - acc: 0.9246 - val_loss: 0.3575 - val_acc: 0.8910\n",
      "Epoch 56/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2093 - acc: 0.9258 - val_loss: 0.4630 - val_acc: 0.8720\n",
      "Epoch 57/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2013 - acc: 0.9287 - val_loss: 0.3876 - val_acc: 0.8840\n",
      "Epoch 58/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.2079 - acc: 0.9259 - val_loss: 0.3500 - val_acc: 0.8940\n",
      "Epoch 59/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2025 - acc: 0.9291 - val_loss: 0.3945 - val_acc: 0.8880\n",
      "Epoch 60/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.2002 - acc: 0.9283 - val_loss: 0.3782 - val_acc: 0.8750\n",
      "Epoch 61/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1942 - acc: 0.9322 - val_loss: 0.3739 - val_acc: 0.8870\n",
      "Epoch 62/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1974 - acc: 0.9310 - val_loss: 0.4056 - val_acc: 0.8850\n",
      "Epoch 63/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1981 - acc: 0.9302 - val_loss: 0.3762 - val_acc: 0.8880\n",
      "Epoch 64/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1884 - acc: 0.9336 - val_loss: 0.3934 - val_acc: 0.8910\n",
      "Epoch 65/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1864 - acc: 0.9352 - val_loss: 0.3447 - val_acc: 0.8880\n",
      "Epoch 66/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1831 - acc: 0.9354 - val_loss: 0.4163 - val_acc: 0.8800\n",
      "Epoch 67/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1876 - acc: 0.9339 - val_loss: 0.4526 - val_acc: 0.8660\n",
      "Epoch 68/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1795 - acc: 0.9364 - val_loss: 0.3795 - val_acc: 0.8880\n",
      "Epoch 69/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1756 - acc: 0.9373 - val_loss: 0.3890 - val_acc: 0.8690\n",
      "Epoch 70/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1783 - acc: 0.9379 - val_loss: 0.3247 - val_acc: 0.8960\n",
      "Epoch 71/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1808 - acc: 0.9361 - val_loss: 0.3461 - val_acc: 0.9000\n",
      "Epoch 72/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1693 - acc: 0.9411 - val_loss: 0.3566 - val_acc: 0.8970\n",
      "Epoch 73/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1733 - acc: 0.9381 - val_loss: 0.3749 - val_acc: 0.8960\n",
      "Epoch 74/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1711 - acc: 0.9397 - val_loss: 0.3259 - val_acc: 0.9010\n",
      "Epoch 75/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1719 - acc: 0.9385 - val_loss: 0.4388 - val_acc: 0.8740\n",
      "Epoch 76/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1692 - acc: 0.9395 - val_loss: 0.3860 - val_acc: 0.8870\n",
      "Epoch 77/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1662 - acc: 0.9417 - val_loss: 0.3649 - val_acc: 0.8940\n",
      "Epoch 78/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1633 - acc: 0.9417 - val_loss: 0.3783 - val_acc: 0.8910\n",
      "Epoch 79/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1618 - acc: 0.9432 - val_loss: 0.3524 - val_acc: 0.8940\n",
      "Epoch 80/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1601 - acc: 0.9431 - val_loss: 0.3619 - val_acc: 0.8900\n",
      "Epoch 81/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1593 - acc: 0.9436 - val_loss: 0.3990 - val_acc: 0.8830\n",
      "Epoch 82/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1624 - acc: 0.9430 - val_loss: 0.4018 - val_acc: 0.8890\n",
      "Epoch 83/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1577 - acc: 0.9449 - val_loss: 0.3658 - val_acc: 0.8940\n",
      "Epoch 84/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1587 - acc: 0.9442 - val_loss: 0.3726 - val_acc: 0.8950\n",
      "Epoch 85/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1552 - acc: 0.9460 - val_loss: 0.3672 - val_acc: 0.8960\n",
      "Epoch 86/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1490 - acc: 0.9474 - val_loss: 0.3975 - val_acc: 0.8860\n",
      "Epoch 87/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1523 - acc: 0.9461 - val_loss: 0.3913 - val_acc: 0.8820\n",
      "Epoch 88/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1510 - acc: 0.9461 - val_loss: 0.3697 - val_acc: 0.8880\n",
      "Epoch 89/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1504 - acc: 0.9479 - val_loss: 0.3288 - val_acc: 0.9020\n",
      "Epoch 90/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1466 - acc: 0.9487 - val_loss: 0.3727 - val_acc: 0.8870\n",
      "Epoch 91/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1485 - acc: 0.9469 - val_loss: 0.3534 - val_acc: 0.8870\n",
      "Epoch 92/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1458 - acc: 0.9472 - val_loss: 0.4259 - val_acc: 0.8820\n",
      "Epoch 93/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1458 - acc: 0.9488 - val_loss: 0.4033 - val_acc: 0.8970\n",
      "Epoch 94/100\n",
      "383/382 [==============================] - 15s 40ms/step - loss: 0.1436 - acc: 0.9491 - val_loss: 0.3539 - val_acc: 0.8930\n",
      "Epoch 95/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1419 - acc: 0.9498 - val_loss: 0.3523 - val_acc: 0.8980\n",
      "Epoch 96/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1420 - acc: 0.9498 - val_loss: 0.3480 - val_acc: 0.8880\n",
      "Epoch 97/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1412 - acc: 0.9502 - val_loss: 0.3665 - val_acc: 0.9020\n",
      "Epoch 98/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1395 - acc: 0.9501 - val_loss: 0.4157 - val_acc: 0.8890\n",
      "Epoch 99/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1367 - acc: 0.9522 - val_loss: 0.3378 - val_acc: 0.9010\n",
      "Epoch 100/100\n",
      "383/382 [==============================] - 15s 39ms/step - loss: 0.1360 - acc: 0.9525 - val_loss: 0.4216 - val_acc: 0.8870\n"
     ]
    }
   ],
   "source": [
    "lrate = 5e-4\n",
    "epochs = 100\n",
    "bsize = 128\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(32,32,3)),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=lrate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# baseline_history = model.fit(x_train, y_train, epochs=epochs, batch_size=bsize, validation_data=(x_val, y_val))\n",
    "\n",
    "# train with image augmentation\n",
    "augmentation_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=bsize), steps_per_epoch = len(x_train) / bsize, epochs=epochs, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 69us/step\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test,y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate result:  [0.48752272262573243, 0.8714]\n"
     ]
    }
   ],
   "source": [
    "print(\"evaluate result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print('predictions shape:', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (2500, 10)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "predictions = model.predict(x_final)\n",
    "print('predictions shape:', predictions.shape)\n",
    "\n",
    "with open('CIFAR10_result.csv', mode='w') as result_file:\n",
    "    writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['ID', 'Class'])\n",
    "    i = 1\n",
    "    for p in predictions:\n",
    "        writer.writerow([i, np.argmax(p)])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
