{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(histories, key='loss'):\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                       '--', label=name.title()+' Val')\n",
    "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "             label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([0,max(history.epoch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_history(histories, key='accuracy'):\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    for name, history in histories:\n",
    "        val = plt.plot(history.epoch, history.history['val_'+key],\n",
    "                       '--', label=name.title()+' Val')\n",
    "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(),\n",
    "             label=name.title()+' Train')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(key.replace('_',' ').title())\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim([0,max(history.epoch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import glob\n",
    "import cv2 \n",
    "import numpy as np\n",
    "def load_data():\n",
    "    IMG_SIZE = 150\n",
    "    train_path = \"./FLOWER/flowers/\"\n",
    "    final_path = \"./FLOWER/unlabel-flowers/\"\n",
    "    # TRAINING\n",
    "    cat = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "    i = 0\n",
    "    cat_index = 0\n",
    "    for c in cat:\n",
    "        file_names = glob.glob(train_path+c+\"/*.jpg\")\n",
    "        print(cat_index)\n",
    "        for f in file_names:\n",
    "            img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "#             img = load_img(f)\n",
    "            if i == 0:\n",
    "                x_train = [img_to_array(img)]\n",
    "                y_train = [[cat_index]]\n",
    "            else:\n",
    "                x_train = np.append(x_train, [img_to_array(img)], axis=0)\n",
    "                y_train = np.append(y_train, [[cat_index]], axis=0)\n",
    "            i += 1\n",
    "        cat_index += 1\n",
    "    # FINAL\n",
    "    final_img_size = 175\n",
    "    for i in range(1, final_img_size+1):\n",
    "        img = cv2.imread(final_path+str(i)+'.jpg', cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "#         img = load_img(final_path+str(i)+'.jpg')\n",
    "        if i == 1:\n",
    "            x_final = [img_to_array(img)]\n",
    "        else:\n",
    "            x_final = np.append(x_final, [img_to_array(img)], axis=0)\n",
    "            \n",
    "    return (x_train, y_train), (x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_final) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape\n",
    "x_train = x_train.reshape(x_train.shape[0], 150, 150, 3)\n",
    "x_final = x_final.reshape(x_final.shape[0], 150, 150, 3)\n",
    "\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_final = x_final.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4148, 150, 150, 3)\n",
      "Number of images in x_train 4148\n",
      "Number of images in x_final 175\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_final', x_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "# normalize -1~1\n",
    "x_train = (x_train-127.5)/127.5\n",
    "x_final = (x_final-127.5)/127.5\n",
    "\n",
    "# validation\n",
    "x_val = x_train[-1000:]\n",
    "y_val = y_train[-1000:]\n",
    "x_train = x_train[:-1000]\n",
    "y_train = y_train[:-1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up image augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 87616)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               44859904  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 44,884,293\n",
      "Trainable params: 44,883,077\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "25/24 [==============================] - 14s 571ms/step - loss: 1.8917 - acc: 0.5669 - val_loss: 1.3555 - val_acc: 0.5162\n",
      "Epoch 2/50\n",
      "25/24 [==============================] - 13s 514ms/step - loss: 1.1517 - acc: 0.6467 - val_loss: 1.9891 - val_acc: 0.3640\n",
      "Epoch 3/50\n",
      "25/24 [==============================] - 13s 509ms/step - loss: 0.9821 - acc: 0.6804 - val_loss: 2.8337 - val_acc: 0.3409\n",
      "Epoch 4/50\n",
      "25/24 [==============================] - 13s 509ms/step - loss: 0.8636 - acc: 0.7122 - val_loss: 3.3171 - val_acc: 0.3323\n",
      "Epoch 5/50\n",
      "25/24 [==============================] - 13s 509ms/step - loss: 0.8128 - acc: 0.7274 - val_loss: 3.6143 - val_acc: 0.3374\n",
      "Epoch 6/50\n",
      "25/24 [==============================] - 13s 500ms/step - loss: 0.7437 - acc: 0.7540 - val_loss: 4.1944 - val_acc: 0.3326\n",
      "Epoch 7/50\n",
      "25/24 [==============================] - 12s 494ms/step - loss: 0.6919 - acc: 0.7654 - val_loss: 4.2475 - val_acc: 0.3361\n",
      "Epoch 8/50\n",
      "25/24 [==============================] - 13s 520ms/step - loss: 0.6647 - acc: 0.7659 - val_loss: 4.1893 - val_acc: 0.3564\n",
      "Epoch 9/50\n",
      "25/24 [==============================] - 13s 513ms/step - loss: 0.6232 - acc: 0.7900 - val_loss: 4.0873 - val_acc: 0.3621\n",
      "Epoch 10/50\n",
      "25/24 [==============================] - 13s 511ms/step - loss: 0.5888 - acc: 0.7969 - val_loss: 3.7360 - val_acc: 0.3936\n",
      "Epoch 11/50\n",
      "25/24 [==============================] - 13s 525ms/step - loss: 0.5647 - acc: 0.8047 - val_loss: 3.0167 - val_acc: 0.4273\n",
      "Epoch 12/50\n",
      "25/24 [==============================] - 13s 525ms/step - loss: 0.5394 - acc: 0.8120 - val_loss: 3.0844 - val_acc: 0.4330\n",
      "Epoch 13/50\n",
      "25/24 [==============================] - 13s 508ms/step - loss: 0.5013 - acc: 0.8150 - val_loss: 2.6664 - val_acc: 0.4584\n",
      "Epoch 14/50\n",
      "25/24 [==============================] - 12s 488ms/step - loss: 0.5153 - acc: 0.8243 - val_loss: 2.4310 - val_acc: 0.4797\n",
      "Epoch 15/50\n",
      "25/24 [==============================] - 13s 517ms/step - loss: 0.4670 - acc: 0.8305 - val_loss: 1.9271 - val_acc: 0.5175\n",
      "Epoch 16/50\n",
      "25/24 [==============================] - 12s 480ms/step - loss: 0.4379 - acc: 0.8410 - val_loss: 1.5436 - val_acc: 0.5705\n",
      "Epoch 17/50\n",
      "25/24 [==============================] - 12s 466ms/step - loss: 0.4516 - acc: 0.8462 - val_loss: 1.0494 - val_acc: 0.6550\n",
      "Epoch 18/50\n",
      "25/24 [==============================] - 11s 447ms/step - loss: 0.4002 - acc: 0.8563 - val_loss: 1.0655 - val_acc: 0.6738\n",
      "Epoch 19/50\n",
      "25/24 [==============================] - 12s 462ms/step - loss: 0.4450 - acc: 0.8463 - val_loss: 0.6270 - val_acc: 0.7687\n",
      "Epoch 20/50\n",
      "25/24 [==============================] - 11s 440ms/step - loss: 0.4267 - acc: 0.8455 - val_loss: 0.5873 - val_acc: 0.7691\n",
      "Epoch 21/50\n",
      "25/24 [==============================] - 11s 460ms/step - loss: 0.3918 - acc: 0.8569 - val_loss: 0.5554 - val_acc: 0.7732\n",
      "Epoch 22/50\n",
      "25/24 [==============================] - 11s 444ms/step - loss: 0.4134 - acc: 0.8453 - val_loss: 0.4544 - val_acc: 0.8402\n",
      "Epoch 23/50\n",
      "25/24 [==============================] - 12s 462ms/step - loss: 0.3819 - acc: 0.8613 - val_loss: 0.3708 - val_acc: 0.8590\n",
      "Epoch 24/50\n",
      "25/24 [==============================] - 11s 449ms/step - loss: 0.3643 - acc: 0.8682 - val_loss: 0.3527 - val_acc: 0.8631\n",
      "Epoch 25/50\n",
      "25/24 [==============================] - 12s 466ms/step - loss: 0.3714 - acc: 0.8668 - val_loss: 0.2657 - val_acc: 0.9053\n",
      "Epoch 26/50\n",
      "25/24 [==============================] - 11s 441ms/step - loss: 0.3577 - acc: 0.8685 - val_loss: 0.2916 - val_acc: 0.8901\n",
      "Epoch 27/50\n",
      "25/24 [==============================] - 11s 446ms/step - loss: 0.3546 - acc: 0.8691 - val_loss: 0.2473 - val_acc: 0.9104\n",
      "Epoch 28/50\n",
      "25/24 [==============================] - 11s 448ms/step - loss: 0.3563 - acc: 0.8635 - val_loss: 0.2582 - val_acc: 0.9057\n",
      "Epoch 29/50\n",
      "25/24 [==============================] - 12s 472ms/step - loss: 0.3292 - acc: 0.8834 - val_loss: 0.2537 - val_acc: 0.9037\n",
      "Epoch 30/50\n",
      "25/24 [==============================] - 11s 455ms/step - loss: 0.3451 - acc: 0.8724 - val_loss: 0.2058 - val_acc: 0.9323\n",
      "Epoch 31/50\n",
      "25/24 [==============================] - 11s 444ms/step - loss: 0.3015 - acc: 0.8880 - val_loss: 0.1909 - val_acc: 0.9346\n",
      "Epoch 32/50\n",
      "25/24 [==============================] - 11s 449ms/step - loss: 0.3014 - acc: 0.8906 - val_loss: 0.1814 - val_acc: 0.9390\n",
      "Epoch 33/50\n",
      "25/24 [==============================] - 11s 450ms/step - loss: 0.2971 - acc: 0.8952 - val_loss: 0.2255 - val_acc: 0.9209\n",
      "Epoch 34/50\n",
      "25/24 [==============================] - 11s 458ms/step - loss: 0.2815 - acc: 0.8992 - val_loss: 0.2134 - val_acc: 0.9206\n",
      "Epoch 35/50\n",
      "25/24 [==============================] - 11s 443ms/step - loss: 0.2661 - acc: 0.9030 - val_loss: 0.1628 - val_acc: 0.9530\n",
      "Epoch 36/50\n",
      "25/24 [==============================] - 11s 455ms/step - loss: 0.2625 - acc: 0.9039 - val_loss: 0.1507 - val_acc: 0.9536\n",
      "Epoch 37/50\n",
      "25/24 [==============================] - 11s 444ms/step - loss: 0.2659 - acc: 0.9083 - val_loss: 0.1591 - val_acc: 0.9473\n",
      "Epoch 38/50\n",
      "25/24 [==============================] - 11s 451ms/step - loss: 0.2508 - acc: 0.9088 - val_loss: 0.1518 - val_acc: 0.9530\n",
      "Epoch 39/50\n",
      "25/24 [==============================] - 11s 446ms/step - loss: 0.2468 - acc: 0.9085 - val_loss: 0.1411 - val_acc: 0.9571\n",
      "Epoch 40/50\n",
      "25/24 [==============================] - 11s 443ms/step - loss: 0.2724 - acc: 0.9044 - val_loss: 0.1792 - val_acc: 0.9361\n",
      "Epoch 41/50\n",
      "25/24 [==============================] - 11s 450ms/step - loss: 0.2588 - acc: 0.9149 - val_loss: 0.1510 - val_acc: 0.9571\n",
      "Epoch 42/50\n",
      "25/24 [==============================] - 11s 456ms/step - loss: 0.2406 - acc: 0.9161 - val_loss: 0.1584 - val_acc: 0.9431\n",
      "Epoch 43/50\n",
      "25/24 [==============================] - 12s 462ms/step - loss: 0.2447 - acc: 0.9075 - val_loss: 0.1255 - val_acc: 0.9616\n",
      "Epoch 44/50\n",
      "25/24 [==============================] - 11s 451ms/step - loss: 0.2280 - acc: 0.9174 - val_loss: 0.1179 - val_acc: 0.9647\n",
      "Epoch 45/50\n",
      "25/24 [==============================] - 11s 451ms/step - loss: 0.2035 - acc: 0.9258 - val_loss: 0.1223 - val_acc: 0.9622\n",
      "Epoch 46/50\n",
      "25/24 [==============================] - 11s 449ms/step - loss: 0.2186 - acc: 0.9214 - val_loss: 0.1341 - val_acc: 0.9530\n",
      "Epoch 47/50\n",
      "25/24 [==============================] - 11s 454ms/step - loss: 0.2056 - acc: 0.9216 - val_loss: 0.1327 - val_acc: 0.9568\n",
      "Epoch 48/50\n",
      "25/24 [==============================] - 12s 474ms/step - loss: 0.2206 - acc: 0.9230 - val_loss: 0.1143 - val_acc: 0.9635\n",
      "Epoch 49/50\n",
      "25/24 [==============================] - 11s 451ms/step - loss: 0.2133 - acc: 0.9252 - val_loss: 0.1179 - val_acc: 0.9651\n",
      "Epoch 50/50\n",
      "25/24 [==============================] - 11s 446ms/step - loss: 0.2183 - acc: 0.9206 - val_loss: 0.1146 - val_acc: 0.9647\n"
     ]
    }
   ],
   "source": [
    "lrate = 5e-4\n",
    "epochs = 50\n",
    "bsize = 128\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(150,150,3)),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "#     tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(axis=-1),\n",
    "#     tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(axis=-1),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(axis=-1),\n",
    "# #     tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "# #     tf.keras.layers.BatchNormalization(axis=-1),\n",
    "#     tf.keras.layers.MaxPooling2D((2,2)),\n",
    "# #     tf.keras.layers.Dropout(0.4),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "optimizer = tf.keras.optimizers.Adam(lr=lrate)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# baseline_history = model.fit(x_train, y_train, epochs=epochs, batch_size=bsize, validation_data=(x_val, y_val))\n",
    "\n",
    "# train with image augmentation\n",
    "augmentation_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=bsize), steps_per_epoch = len(x_train) / bsize, epochs=epochs, validation_data=(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (175, 5)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "predictions = model.predict(x_final)\n",
    "print('predictions shape:', predictions.shape)\n",
    "\n",
    "with open('FLOWER_result.csv', mode='w') as result_file:\n",
    "    writer = csv.writer(result_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['ID', 'Class'])\n",
    "    i = 1\n",
    "    for p in predictions:\n",
    "        writer.writerow([i, np.argmax(p)+1])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
